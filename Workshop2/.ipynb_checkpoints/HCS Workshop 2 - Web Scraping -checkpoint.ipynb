{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HCS Workshop 2, Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Will Cooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "# import requests package and set up page\n",
    "\n",
    "import requests\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "print(page.status_code)\n",
    "print(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "\n",
      "<html>\n",
      "<head>\n",
      "<title>A simple example page</title>\n",
      "</head>\n",
      "<body>\n",
      "<p>Here is some simple content for this page.</p>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# import BeautifulSoup and make a \"BeautifulSoup object\"\n",
    "# sudo apt-get install python-bs4\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "<p>Here is some simple content for this page.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list soup children, title, etc. \n",
    "\n",
    "list(soup.children)\n",
    "list(soup.title)\n",
    "print(soup.title.parent.name)\n",
    "print(soup.p)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more printing\n",
    "html = list(soup.children)[2]\n",
    "list(html.children)\n",
    "body = list(html.children)[3]\n",
    "list(body.children)\n",
    "p = list(body.children)[1]\n",
    "p.get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find function\n",
    "soup.find('p')\n",
    "soup.find('head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more sources? \n",
    "# https://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "# https://www.dataquest.io/blog/web-scraping-tutorial-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"tombstone-container\">\n",
      " <p class=\"period-name\">\n",
      "  Today\n",
      "  <br/>\n",
      "  <br/>\n",
      " </p>\n",
      " <p>\n",
      "  <img alt=\"Today: Mostly sunny, with a high near 70. Light west northwest wind becoming west 5 to 10 mph in the afternoon. \" class=\"forecast-icon\" src=\"newimages/medium/sct.png\" title=\"Today: Mostly sunny, with a high near 70. Light west northwest wind becoming west 5 to 10 mph in the afternoon. \"/>\n",
      " </p>\n",
      " <p class=\"short-desc\">\n",
      "  Mostly Sunny\n",
      " </p>\n",
      " <p class=\"temp temp-high\">\n",
      "  High: 70 °F\n",
      " </p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get('http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "seven_day = soup.find(id = 'seven-day-forecast')\n",
    "forecast_items = seven_day.find_all(class_='tombstone-container')\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today\n",
      "Mostly Sunny\n",
      "High: 70 °F\n"
     ]
    }
   ],
   "source": [
    "period = tonight.find(class_='period-name').get_text()\n",
    "short_desc = tonight.find(class_='short-desc').get_text()\n",
    "temp = tonight.find(class_='temp').get_text()\n",
    "print(period)\n",
    "print(short_desc)\n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Goldman Sachs Gr\n",
      "\n",
      "\n",
      "205.73\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.95 %\n",
      "\n",
      "\n",
      "3.93\n",
      "\n",
      "\n",
      "2:11:48 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "IBM\n",
      "\n",
      "\n",
      "124.18\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.78 %\n",
      "\n",
      "\n",
      "2.17\n",
      "\n",
      "\n",
      "2:12:07 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "Chevron\n",
      "\n",
      "\n",
      "73.96\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.73 %\n",
      "\n",
      "\n",
      "1.26\n",
      "\n",
      "\n",
      "2:12:13 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "Intel\n",
      "\n",
      "\n",
      "52.47\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.51 %\n",
      "\n",
      "\n",
      "0.78\n",
      "\n",
      "\n",
      "2:11:39 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "3M\n",
      "\n",
      "\n",
      "165.20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.51 %\n",
      "\n",
      "\n",
      "2.45\n",
      "\n",
      "\n",
      "2:12:06 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "Home Depot\n",
      "\n",
      "\n",
      "280.52\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.56 %\n",
      "\n",
      "\n",
      "-1.58\n",
      "\n",
      "\n",
      "2:12:06 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "Microsoft\n",
      "\n",
      "\n",
      "208.66\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-0.82 %\n",
      "\n",
      "\n",
      "-1.72\n",
      "\n",
      "\n",
      "2:12:33 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "Merck\n",
      "\n",
      "\n",
      "80.40\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-1.03 %\n",
      "\n",
      "\n",
      "-0.84\n",
      "\n",
      "\n",
      "2:12:26 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "Apple\n",
      "\n",
      "\n",
      "115.25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-1.07 %\n",
      "\n",
      "\n",
      "-1.25\n",
      "\n",
      "\n",
      "2:12:24 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "\n",
      "\n",
      "Boeing Co\n",
      "\n",
      "\n",
      "165.74\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-3.19 %\n",
      "\n",
      "\n",
      "-5.46\n",
      "\n",
      "\n",
      "2:12:30 PM\n",
      "\n",
      "\n",
      "----------------\n",
      "['Goldman Sachs Gr', 'IBM', 'Chevron', 'Intel', '3M', 'Home Depot', 'Microsoft', 'Merck', 'Apple', 'Boeing Co']\n"
     ]
    }
   ],
   "source": [
    "# 'https://markets.businessinsider.com/stocks'\n",
    "page = requests.get('https://markets.businessinsider.com/stocks')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "stocks = soup.find(id='shares_topflop_StockPricesSharesTopFlop')\n",
    "imte = stocks.find('a')\n",
    "\n",
    "prices = stocks.find_all(class_='row-hover')\n",
    "\n",
    "\n",
    "for price in prices:\n",
    "    print(price.get_text())\n",
    "    print('----------------')\n",
    "    \n",
    "names = []\n",
    "\n",
    "for i in range(len(prices)):\n",
    "    names.append(prices[i].find('a').get_text())\n",
    "\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/stocks/aapl-stock\" title=\"Apple-stock\">Apple</a>]\n"
     ]
    }
   ],
   "source": [
    "# regular expressions, searching by text \n",
    "# https://docs.python.org/3/library/re.html\n",
    "\n",
    "import re\n",
    "\n",
    "bruh = stocks.find_all('a', text = re.compile(\"Apple\"))\n",
    "print(bruh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lady Antebellum - Hello World - YouTube\n",
      "---\n",
      "\"Hello, World!\" program - Wikipedia\n",
      "---\n",
      "Hello, World! - Learn Python - Free Interactive Python Tutorial\n",
      "---\n",
      "Hello World · GitHub Guides\n",
      "---\n",
      "Hello World Studio\n",
      "---\n",
      "Hello World! - Manning\n",
      "---\n",
      "HelloWorld - Digital promotions & loyalty programs for the world's ...\n",
      "---\n",
      "Hello World! - GNU Project - Free Software Foundation (FSF)\n",
      "---\n",
      "Lesson: A Closer Look at the \"Hello World!\" Application (The Java ...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/47928608/how-to-use-beautifulsoup-to-parse-google-search-results-in-python\n",
    "# quick example of using BeautifulSoup to Google for you \n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import webbrowser\n",
    "\n",
    "text = 'hello world'\n",
    "text = urllib.parse.quote_plus(text)\n",
    "\n",
    "url = 'https://google.com/search?q=' + text\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('output.html', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "webbrowser.open('output.html')\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "for g in soup.find_all(class_='BNeawe vvjwJb AP7Wnd'):\n",
    "    print(g.get_text())\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
